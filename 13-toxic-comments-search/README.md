## [Проект 13. Поиск токсичных комментариев (с BERT)](13-search-for-toxic-comments--bert--ml-for-texts--nlp.ipynb)


### Цель проекта

Провести исследование с целью построения модели машинного обучения, которая поможет классифицировать комментарии на позитивные и негативные.

Результаты исследования позволят магазину искать токсичные комментарии и отправлять их на модерацию.

Входные данные: набор данных с разметкой о токсичности правок.


### Задачи проекта

Решим поставленную в проекте задачу **на базе нейронной сети *BERT***.

1. Изучить данные.
2. Сэмплировать данные.
3. Разделить сэмплы на выборки.
4. Получить эмбеддинги.
5. Построить и обучить модели.
6. Протестировать лучшую модель.
7. Написать общий вывод.

Построим модель со значением метрики качества *F1* не меньше 0.75.


### Навыки и инструменты

- catboost
- lightgbm
- numpy
- pandas
- python
- sklearn.ensemble
- sklearn.linear_model
- sklearn.metrics
- sklearn.model_selection
- sklearn.utils.class_weight
- torch
- transformers


### Общий вывод

1. Лучшая модель градиентного бустинга `LGBMClassifier` на тестовой выборке имеет значение метрики оценки качества *F1* = 0.95.
2. Значение метрики *F1* на тестовой выборке превышает 0.75, что соответсвует изначальному требованию в условии задачи проекта.
